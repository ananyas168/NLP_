{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMgPbFHE75SIXYWn2aKvoBB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananyas168/NLP_/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfobyobnQJ7O"
      },
      "source": [
        "import csv,sys\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split \n",
        "from sklearn.metrics import confusion_matrix,accuracy_score, precision_score, recall_score, f1_score\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yNM2ZYPilF2"
      },
      "source": [
        "f_train_data = open('/content/assignment1_training_data.txt','r')\n",
        "#print(f)\n",
        "reader_train_data = list(csv.reader(f_train_data,delimiter='\\t'))\n",
        "\n",
        "data_train=[];\n",
        "for item in reader_train_data:\n",
        "    #labels.append(item[0])    \n",
        "    data_train.append(item[0])\n",
        "\n",
        "f_train_label = open('/content/assignment1_training_data_labels.txt','r')\n",
        "#print(f)\n",
        "reader_train_label = list(csv.reader(f_train_label,delimiter='\\t'))\n",
        "\n",
        "labels_train=[];\n",
        "for item in reader_train_label:\n",
        "    #labels.append(item[0])    \n",
        "    labels_train.append(item[0])\n",
        "\n",
        "f_test_data = open('/content/assignment1_test_data.txt','r')\n",
        "#print(f)\n",
        "reader_test_data = list(csv.reader(f_test_data,delimiter='\\t'))\n",
        "\n",
        "data_test=[];\n",
        "for item in reader_test_data:\n",
        "    #labels.append(item[0])    \n",
        "    data_test.append(item[0])  \n",
        "\n",
        "analyzer = CountVectorizer().build_analyzer()\n",
        "\n",
        "def stemmed_words(doc):\n",
        "  return (PorterStemmer().stem(w) for w in analyzer(doc))\n",
        "\n",
        "def lemmatized_words(doc):\n",
        "  return (WordNetLemmatizer().lemmatize(w) for w in analyzer(doc))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHgnK9c9cuGK"
      },
      "source": [
        "# print(analyzer(data_train[0]))\n",
        "# t= lemmatized_words(data_train[0])\n",
        "# print(t[0])\n",
        "# print(data_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCD3-T8_RhP9"
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text, type):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    # text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    # text = text.lower() # lowercase text\n",
        "    # text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    # text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    #text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    #text = ' '.join(word for word in analyzer(text) if word not in STOPWORDS) # delete stopwors from text\n",
        "    #text = ' '.join(WordNetLemmatizer().lemmatize(w) for w in analyzer(text))\n",
        "    if type == 1:\n",
        "      text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    elif type == 2:\n",
        "      #print('only_stop')\n",
        "      text = ' '.join(word for word in analyzer(text) if word not in STOPWORDS)\n",
        "    \n",
        "    elif type == 3:\n",
        "      text = ' '.join(PorterStemmer().stem(w) for w in analyzer(text))\n",
        "    elif type == 4:\n",
        "      text = ' '.join(WordNetLemmatizer().lemmatize(w) for w in analyzer(text))\n",
        "    elif type == 5:\n",
        "      text = ' '.join(word for word in analyzer(text) if word not in STOPWORDS)\n",
        "      text = ' '.join(PorterStemmer().stem(w) for w in analyzer(text))\n",
        "    elif type == 6:\n",
        "      text = ' '.join(word for word in analyzer(text) if word not in STOPWORDS)\n",
        "      text = ' '.join(WordNetLemmatizer().lemmatize(w) for w in analyzer(text))\n",
        "    return text\n",
        "\n",
        "df_train = pd.DataFrame(data_train)\n",
        "# print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "# df_train[0] = df_train[0].apply(clean_text)\n",
        "# print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "#df_train[0]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYZOL8EMRsOe"
      },
      "source": [
        "# df_train = pd.DataFrame(data_train)\n",
        "# print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "# df_train[0] = df_train[0].apply(clean_text)\n",
        "# print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "# #df_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5em4s-AaUDqt"
      },
      "source": [
        "# df_test = pd.DataFrame(data_test)\n",
        "# print('words_per before',df_test[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "# df_test[0] = df_test[0].apply(clean_text)\n",
        "# print('words_per after',df_test[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "# df_test[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbST3RmCisqU"
      },
      "source": [
        "data_test\n",
        "#labels_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "QUFTTcZ5TUza",
        "outputId": "c354b4f2-83d8-4824-eb9f-27d6d805b6cc"
      },
      "source": [
        "import pandas as pd\n",
        "new_row = {'model':['demo'],'precision': [0],'recall':[0], 'micro_f1': [0],'macro_f1':[0] }\n",
        "#new_row = {'model':['demo'],'preprocessing_used':['demo'],'precision': [0],'recall':[0], 'micro_f1': [0],'macro_f1':[0] }\n",
        "df0= pd.DataFrame(new_row) \n",
        "df0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>micro_f1</th>\n",
              "      <th>macro_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>demo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model  precision  recall  micro_f1  macro_f1\n",
              "0  demo          0       0         0         0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9644_C0jrjA"
      },
      "source": [
        "#def evaluation(trn_data,trn_cat,tst_cat,tst_data,predicted,model, df0):\n",
        "def evaluation(tst_cat,predicted,model, df0):\n",
        "    # print('\\n Total documents in the training set: '+str(len(trn_data))+'\\n')    \n",
        "    # print('\\n Total documents in the test set: '+str(len(tst_data))+'\\n')\n",
        "    print ('\\n Confusion Matrix \\n')  \n",
        "    print (confusion_matrix(tst_cat, predicted))  \n",
        "\n",
        "    pr=precision_score(tst_cat, predicted, average='macro') \n",
        "    print ('\\n Precision:'+str(pr)) \n",
        "\n",
        "    rl=recall_score(tst_cat, predicted, average='macro') \n",
        "    print ('\\n Recall:'+str(rl))\n",
        "\n",
        "    fm1=f1_score(tst_cat, predicted, average='macro') \n",
        "    print ('\\n Macro Averaged F1-Score :'+str(fm1))\n",
        "\n",
        "    fm2=f1_score(tst_cat, predicted, average='micro') \n",
        "    print ('\\n Mircro Averaged F1-Score:'+str(fm2))\n",
        "    #new_row = {'model':model,'preprocessing_used':analyser,'precision': pr,'recall':rl, 'micro_f1': fm1,'macro_f1':fm2 }\n",
        "    new_row = {'model':model,'precision': pr,'recall':rl, 'micro_f1': fm1,'macro_f1':fm2 }\n",
        "    df0= df0.append(new_row,ignore_index=True) \n",
        "    print(df0)\n",
        "    return df0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0XdRv0yQA79"
      },
      "source": [
        "#to compare best preprocessing technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-9bFgksp4DiQ",
        "outputId": "a3785876-65c8-4357-a108-4d5772f51894"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/assignment1_test_data_labels.txt', header =None)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>453 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0\n",
              "0    positive\n",
              "1     neutral\n",
              "2    negative\n",
              "3     neutral\n",
              "4    positive\n",
              "..        ...\n",
              "448  negative\n",
              "449   neutral\n",
              "450   neutral\n",
              "451  positive\n",
              "452   neutral\n",
              "\n",
              "[453 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "y3hhHvmd4d1U",
        "outputId": "3dc15aa9-b215-4122-8d3d-b1ee02a1f03b"
      },
      "source": [
        "df1 = pd.read_csv('/content/ananya_singha_18032_test_labels_csv.csv')\n",
        "df1= df1.drop(columns= ['Unnamed: 0'] , axis =0)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>453 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       labels\n",
              "0    positive\n",
              "1     neutral\n",
              "2    negative\n",
              "3     neutral\n",
              "4    positive\n",
              "..        ...\n",
              "448  negative\n",
              "449   neutral\n",
              "450   neutral\n",
              "451  positive\n",
              "452   neutral\n",
              "\n",
              "[453 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "JJCn23Vy5owT",
        "outputId": "d32fced6-a1ef-479e-f16d-48171b5fbaa2"
      },
      "source": [
        "evaluation(df,df1,'hh',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 52   0   9]\n",
            " [  3 264  11]\n",
            " [  8  16  90]]\n",
            "\n",
            " Precision:0.8621452621452622\n",
            "\n",
            " Recall:0.863857662791251\n",
            "\n",
            " Macro Averaged F1-Score :0.8628392217101895\n",
            "\n",
            " Mircro Averaged F1-Score:0.8962472406181016\n",
            "  model  precision    recall  micro_f1  macro_f1\n",
            "0  demo   0.000000  0.000000  0.000000  0.000000\n",
            "1    hh   0.862145  0.863858  0.862839  0.896247\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>micro_f1</th>\n",
              "      <th>macro_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>demo</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hh</td>\n",
              "      <td>0.862145</td>\n",
              "      <td>0.863858</td>\n",
              "      <td>0.862839</td>\n",
              "      <td>0.896247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model  precision    recall  micro_f1  macro_f1\n",
              "0  demo   0.000000  0.000000  0.000000  0.000000\n",
              "1    hh   0.862145  0.863858  0.862839  0.896247"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVUzT1DhNbEV"
      },
      "source": [
        "# word to vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdhL1KQFWqdJ"
      },
      "source": [
        "1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUlw2onXPQHl",
        "outputId": "1f64d398-8d64-4330-93b3-0cdab877f26c"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-26 14:10:03--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.192.136\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.192.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  33.8MB/s    in 48s     \n",
            "\n",
            "2021-09-26 14:10:52 (32.7 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTL1PfUGNaQB"
      },
      "source": [
        "\n",
        "#%%time\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "wv.init_sims(replace=True)\n",
        "\n",
        "\n",
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.vector_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean\n",
        "\n",
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, post) for post in text_list ])\n",
        "\n",
        "\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYcYhdLsm0aK"
      },
      "source": [
        "#no pre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHWGqBFuQa0N",
        "outputId": "9c57d9ce-e6aa-46da-aac1-e5e1b06d84a6"
      },
      "source": [
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "df_test = pd.DataFrame(data_test)\n",
        "df_train[0] = df_train[0].apply(clean_text, args= (1,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')\n",
        "clf.fit(X_train_word_average,train_y)\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "#evaluation(train_x,train_y,test_y,test_x,predicted,'no_preprocessing',df)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'Word2vec','no_preprocessing',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 29410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 38   2  12]\n",
            " [  8 201  10]\n",
            " [ 21  10  61]]\n",
            "\n",
            " Precision:0.8264462809917356\n",
            "\n",
            " Recall:0.8264462809917356\n",
            "\n",
            " Macro Averaged F1-Score :0.7554512916277623\n",
            "\n",
            " Mircro Averaged F1-Score:0.8264462809917356\n",
            "      model preprocessing_used  precision    recall  micro_f1  macro_f1\n",
            "0      demo               demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  Word2vec   no_preprocessing   0.826446  0.826446  0.755451  0.826446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTFOeUNFm6yt"
      },
      "source": [
        "# only_stop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNbC16vIm6I9",
        "outputId": "05705d48-4f25-4bfc-f923-3fb9114957d8"
      },
      "source": [
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text, args= (2,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')\n",
        "clf.fit(X_train_word_average,train_y)\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "#evaluation(train_x,train_y,test_y,test_x,predicted,'no_preprocessing',df)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'Word2vec','only_stopwords',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 23360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 36   1  15]\n",
            " [ 12 194  13]\n",
            " [ 19  11  62]]\n",
            "\n",
            " Precision:0.8044077134986226\n",
            "\n",
            " Recall:0.8044077134986226\n",
            "\n",
            " Macro Averaged F1-Score :0.7331006248653308\n",
            "\n",
            " Mircro Averaged F1-Score:0.8044077134986226\n",
            "      model preprocessing_used  precision    recall  micro_f1  macro_f1\n",
            "0      demo               demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  Word2vec   no_preprocessing   0.826446  0.826446  0.755451  0.826446\n",
            "2  Word2vec     only_stopwords   0.804408  0.804408  0.733101  0.804408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm4fRBftnAuo"
      },
      "source": [
        "# only stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr2KDbp_nABY",
        "outputId": "babb9056-f64c-4898-d4c3-3b4a1f72d171"
      },
      "source": [
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text,args= (3,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')\n",
        "clf.fit(X_train_word_average,train_y)\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "#evaluation(train_x,train_y,test_y,test_x,predicted,'no_preprocessing',df)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'Word2vec','only_stemmed_words',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 34802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n",
            "WARNING:root:cannot compute similarity with no input ['nwc', 'analysi']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 36   5  11]\n",
            " [  9 201   9]\n",
            " [ 24  11  57]]\n",
            "\n",
            " Precision:0.8099173553719008\n",
            "\n",
            " Recall:0.8099173553719008\n",
            "\n",
            " Macro Averaged F1-Score :0.7305386279852181\n",
            "\n",
            " Mircro Averaged F1-Score:0.8099173553719008\n",
            "      model  preprocessing_used  precision    recall  micro_f1  macro_f1\n",
            "0      demo                demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  Word2vec    no_preprocessing   0.826446  0.826446  0.755451  0.826446\n",
            "2  Word2vec      only_stopwords   0.804408  0.804408  0.733101  0.804408\n",
            "3  Word2vec  only_stemmed_words   0.809917  0.809917  0.730539  0.809917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oQmrOMsnDn0"
      },
      "source": [
        "#only lem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s373gibInGjb",
        "outputId": "4086b387-33df-4ee9-cc8d-22080fae3a91"
      },
      "source": [
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text, args= (4,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')\n",
        "clf.fit(X_train_word_average,train_y)\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "#evaluation(train_x,train_y,test_y,test_x,predicted,'no_preprocessing',df)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'Word2vec','only_lemmatized_words',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 34802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 39   4   9]\n",
            " [  9 200  10]\n",
            " [ 18  15  59]]\n",
            "\n",
            " Precision:0.8209366391184573\n",
            "\n",
            " Recall:0.8209366391184573\n",
            "\n",
            " Macro Averaged F1-Score :0.7561255351145952\n",
            "\n",
            " Mircro Averaged F1-Score:0.8209366391184573\n",
            "      model     preprocessing_used  precision    recall  micro_f1  macro_f1\n",
            "0      demo                   demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  Word2vec       no_preprocessing   0.826446  0.826446  0.755451  0.826446\n",
            "2  Word2vec         only_stopwords   0.804408  0.804408  0.733101  0.804408\n",
            "3  Word2vec     only_stemmed_words   0.809917  0.809917  0.730539  0.809917\n",
            "4  Word2vec  only_lemmatized_words   0.820937  0.820937  0.756126  0.820937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9X_HT5QnHk5"
      },
      "source": [
        "#bstem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHV0rkZdnJOW",
        "outputId": "9aaee8fd-3345-4854-c807-84ef2ae0377a"
      },
      "source": [
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text,args= (5,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')\n",
        "clf.fit(X_train_word_average,train_y)\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "#evaluation(train_x,train_y,test_y,test_x,predicted,'no_preprocessing',df)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'Word2vec','stopword + stemmed_words',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 23360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n",
            "WARNING:root:cannot compute similarity with no input ['nwc', 'analysi']\n",
            "WARNING:root:cannot compute similarity with no input ['2007', 'etteplan', 'turnov', 'eur125']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 37   3  12]\n",
            " [ 13 191  15]\n",
            " [ 24  14  54]]\n",
            "\n",
            " Precision:0.7768595041322314\n",
            "\n",
            " Recall:0.7768595041322314\n",
            "\n",
            " Macro Averaged F1-Score :0.7020642090290532\n",
            "\n",
            " Mircro Averaged F1-Score:0.7768595041322314\n",
            "      model        preprocessing_used  precision    recall  micro_f1  macro_f1\n",
            "0      demo                      demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  Word2vec          no_preprocessing   0.826446  0.826446  0.755451  0.826446\n",
            "2  Word2vec            only_stopwords   0.804408  0.804408  0.733101  0.804408\n",
            "3  Word2vec        only_stemmed_words   0.809917  0.809917  0.730539  0.809917\n",
            "4  Word2vec     only_lemmatized_words   0.820937  0.820937  0.756126  0.820937\n",
            "5  Word2vec  stopword + stemmed_words   0.776860  0.776860  0.702064  0.776860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yVJBpihnK2a"
      },
      "source": [
        "#blem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bljZz8HTnNjv",
        "outputId": "9cb74c2c-76cd-403a-f0c7-28400c73dd24"
      },
      "source": [
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text, args= (6,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')\n",
        "clf.fit(X_train_word_average,train_y)\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "#evaluation(train_x,train_y,test_y,test_x,predicted,'no_preprocessing',df)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'Word2vec','stopword +lemmatized_words',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 23360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 33   4  15]\n",
            " [ 13 196  10]\n",
            " [ 19  11  62]]\n",
            "\n",
            " Precision:0.8016528925619835\n",
            "\n",
            " Recall:0.8016528925619835\n",
            "\n",
            " Macro Averaged F1-Score :0.7228226337489687\n",
            "\n",
            " Mircro Averaged F1-Score:0.8016528925619834\n",
            "      model          preprocessing_used  ...  micro_f1  macro_f1\n",
            "0      demo                        demo  ...  0.000000  0.000000\n",
            "1  Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
            "2  Word2vec              only_stopwords  ...  0.733101  0.804408\n",
            "3  Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
            "4  Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
            "5  Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
            "6  Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
            "\n",
            "[7 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWFS3WtzWhRE",
        "outputId": "b844b108-2fc1-4011-adbb-fd8d4ab8cb3d"
      },
      "source": [
        "X_train_word_average"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00792461,  0.02959035, -0.05852022, ...,  0.0332798 ,\n",
              "         0.01659543, -0.11104992],\n",
              "       [-0.05736773,  0.04392793,  0.00666129, ...,  0.07645669,\n",
              "         0.02724556, -0.02557172],\n",
              "       [ 0.02833428, -0.07006926,  0.00771128, ...,  0.00047321,\n",
              "         0.01309755, -0.13545209],\n",
              "       ...,\n",
              "       [-0.0087588 ,  0.0122269 , -0.06028045, ...,  0.03188445,\n",
              "         0.00857286, -0.06301089],\n",
              "       [-0.02876554,  0.0748476 , -0.03488759, ..., -0.01246081,\n",
              "         0.06437585, -0.12530324],\n",
              "       [ 0.07097536, -0.02675731,  0.03519947, ...,  0.04671604,\n",
              "        -0.00218943, -0.02908824]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8VqHHzun7--"
      },
      "source": [
        "# Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWIXSkctQ7-K"
      },
      "source": [
        " # 0. nothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqMrUzRQl1M8",
        "outputId": "db0b248c-4f64-4e55-f1af-4eef0c8cd821"
      },
      "source": [
        "len(data_train),len(labels_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1811, 1811)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUL6rJATQ__D",
        "outputId": "55748db9-5bb9-4e9b-8a62-9de98e3320d7"
      },
      "source": [
        "#clf=MultinomialNB(alpha=0,fit_prior=True, class_prior=None)\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')  \n",
        "vectorizer=TfidfVectorizer(ngram_range=(2,3),token_pattern=r'\\b\\w+\\b')\n",
        "tfidf = vectorizer.fit_transform(data_train)\n",
        "tfidf = tfidf.toarray()\n",
        "\n",
        "# Training and Test Split           \n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(tfidf, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "\n",
        "#Classificaion    \n",
        "clf.fit(train_x,train_y)\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "#evaluation(train_x,train_y,test_y,test_x,predicted,'no_preprocessing',df)\n",
        "df0 = evaluation(train_x,train_y,test_y,test_x,predicted,'Bag of words','no_preprocessing',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 23  14  12]\n",
            " [  0 222   1]\n",
            " [  3  48  40]]\n",
            "\n",
            " Precision:0.7851239669421488\n",
            "\n",
            " Recall:0.7851239669421488\n",
            "\n",
            " Macro Averaged F1-Score :0.6815428446197677\n",
            "\n",
            " Mircro Averaged F1-Score:0.7851239669421488\n",
            "          model          preprocessing_used  ...  micro_f1  macro_f1\n",
            "0          demo                        demo  ...  0.000000  0.000000\n",
            "1      Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
            "2      Word2vec              only_stopwords  ...  0.733101  0.804408\n",
            "3      Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
            "4      Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
            "5      Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
            "6      Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
            "7  Bag of words            no_preprocessing  ...  0.681543  0.785124\n",
            "\n",
            "[8 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjTwmgm4makf",
        "outputId": "f39a7a5b-ebe7-4c7c-aa4a-39223f79bbd5"
      },
      "source": [
        "tfidf.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1811, 47662)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR1SbWAlg5SQ"
      },
      "source": [
        "predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHpSMJoMQZGr"
      },
      "source": [
        "#1. only stop word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh_2lKOgQAAd",
        "outputId": "8328933d-f174-426c-d15c-1d33eb111468"
      },
      "source": [
        "#clf=MultinomialNB(alpha=0,fit_prior=True, class_prior=None) \n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')  \n",
        "vectorizer=TfidfVectorizer(stop_words='english',ngram_range=(2,3),token_pattern=r'\\b\\w+\\b')\n",
        "tfidf = vectorizer.fit_transform(data_train)\n",
        "tfidf = tfidf.toarray()\n",
        "# Training and Test Split           \n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(tfidf, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "\n",
        "#Classificaion    \n",
        "clf.fit(train_x,train_y)\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 =evaluation(train_x,train_y,test_y,test_x,predicted,'Bag of words','only_stopword',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 18  21  10]\n",
            " [  0 220   3]\n",
            " [  6  52  33]]\n",
            "\n",
            " Precision:0.7465564738292011\n",
            "\n",
            " Recall:0.7465564738292011\n",
            "\n",
            " Macro Averaged F1-Score :0.6092052293478663\n",
            "\n",
            " Mircro Averaged F1-Score:0.7465564738292011\n",
            "          model          preprocessing_used  ...  micro_f1  macro_f1\n",
            "0          demo                        demo  ...  0.000000  0.000000\n",
            "1      Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
            "2      Word2vec              only_stopwords  ...  0.733101  0.804408\n",
            "3      Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
            "4      Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
            "5      Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
            "6      Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
            "7  Bag of words            no_preprocessing  ...  0.681543  0.785124\n",
            "8  Bag of words               only_stopword  ...  0.609205  0.746556\n",
            "\n",
            "[9 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP0ktRAFRPc6"
      },
      "source": [
        "#. only stemmed_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkWJqKU1RVWv",
        "outputId": "8125d5df-231a-4bb0-c698-0266ceaa379d"
      },
      "source": [
        "#clf=MultinomialNB(alpha=0,fit_prior=True, class_prior=None) \n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')   \n",
        "vectorizer=TfidfVectorizer(analyzer = stemmed_words,ngram_range=(2,3),token_pattern=r'\\b\\w+\\b')\n",
        "tfidf = vectorizer.fit_transform(data_train)\n",
        "tfidf = tfidf.toarray()\n",
        "# Training and Test Split           \n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(tfidf, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "\n",
        "#Classificaion    \n",
        "clf.fit(train_x,train_y)\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(train_x,train_y,test_y,test_x,predicted,'Bag of words', 'only_stemmed_words',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 38   6   5]\n",
            " [  3 213   7]\n",
            " [  6  13  72]]\n",
            "\n",
            " Precision:0.8898071625344353\n",
            "\n",
            " Recall:0.8898071625344353\n",
            "\n",
            " Macro Averaged F1-Score :0.8502625152625152\n",
            "\n",
            " Mircro Averaged F1-Score:0.8898071625344353\n",
            "          model          preprocessing_used  ...  micro_f1  macro_f1\n",
            "0          demo                        demo  ...  0.000000  0.000000\n",
            "1      Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
            "2      Word2vec              only_stopwords  ...  0.733101  0.804408\n",
            "3      Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
            "4      Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
            "5      Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
            "6      Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
            "7  Bag of words            no_preprocessing  ...  0.681543  0.785124\n",
            "8  Bag of words               only_stopword  ...  0.609205  0.746556\n",
            "9  Bag of words          only_stemmed_words  ...  0.850263  0.889807\n",
            "\n",
            "[10 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeoAfTE-SZHN"
      },
      "source": [
        "# only lemmatized_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTDSSAb5SBGJ",
        "outputId": "2677d3ac-3f3e-41dd-b954-465b3aaedf6d"
      },
      "source": [
        "#clf=MultinomialNB(alpha=0,fit_prior=True, class_prior=None) \n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')  \n",
        "vectorizer=TfidfVectorizer(analyzer = lemmatized_words,ngram_range=(2,3),token_pattern=r'\\b\\w+\\b')\n",
        "tfidf = vectorizer.fit_transform(data_train)\n",
        "tfidf = tfidf.toarray()\n",
        "# Training and Test Split           \n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(tfidf, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "\n",
        "#Classificaion    \n",
        "clf.fit(train_x,train_y)\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0= evaluation(train_x,train_y,test_y,test_x,predicted,'Bag of words', 'only_lemmatized_words',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 37   6   6]\n",
            " [  4 214   5]\n",
            " [  5  14  72]]\n",
            "\n",
            " Precision:0.8898071625344353\n",
            "\n",
            " Recall:0.8898071625344353\n",
            "\n",
            " Macro Averaged F1-Score :0.8476920816339497\n",
            "\n",
            " Mircro Averaged F1-Score:0.8898071625344353\n",
            "           model          preprocessing_used  ...  micro_f1  macro_f1\n",
            "0           demo                        demo  ...  0.000000  0.000000\n",
            "1       Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
            "2       Word2vec              only_stopwords  ...  0.733101  0.804408\n",
            "3       Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
            "4       Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
            "5       Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
            "6       Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
            "7   Bag of words            no_preprocessing  ...  0.681543  0.785124\n",
            "8   Bag of words               only_stopword  ...  0.609205  0.746556\n",
            "9   Bag of words          only_stemmed_words  ...  0.850263  0.889807\n",
            "10  Bag of words       only_lemmatized_words  ...  0.847692  0.889807\n",
            "\n",
            "[11 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLuCoNCTSoNk"
      },
      "source": [
        "# stopword + stemmed_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2th4a_RR-ES",
        "outputId": "7bb3dff1-40ee-4aad-d375-d1263818701a"
      },
      "source": [
        "#clf=MultinomialNB(alpha=0,fit_prior=True, class_prior=None)\n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg')   \n",
        "vectorizer=TfidfVectorizer(stop_words='english',analyzer = stemmed_words, ngram_range=(2,3),token_pattern=r'\\b\\w+\\b')\n",
        "tfidf = vectorizer.fit_transform(data_train)\n",
        "tfidf = tfidf.toarray()\n",
        "# Training and Test Split           \n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(tfidf, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "\n",
        "#Classificaion    \n",
        "clf.fit(train_x,train_y)\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(train_x,train_y,test_y,test_x,predicted, 'Bag of words','stopword + stemmed_words', df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 38   6   5]\n",
            " [  3 213   7]\n",
            " [  6  13  72]]\n",
            "\n",
            " Precision:0.8898071625344353\n",
            "\n",
            " Recall:0.8898071625344353\n",
            "\n",
            " Macro Averaged F1-Score :0.8502625152625152\n",
            "\n",
            " Mircro Averaged F1-Score:0.8898071625344353\n",
            "           model          preprocessing_used  ...  micro_f1  macro_f1\n",
            "0           demo                        demo  ...  0.000000  0.000000\n",
            "1       Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
            "2       Word2vec              only_stopwords  ...  0.733101  0.804408\n",
            "3       Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
            "4       Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
            "5       Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
            "6       Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
            "7   Bag of words            no_preprocessing  ...  0.681543  0.785124\n",
            "8   Bag of words               only_stopword  ...  0.609205  0.746556\n",
            "9   Bag of words          only_stemmed_words  ...  0.850263  0.889807\n",
            "10  Bag of words       only_lemmatized_words  ...  0.847692  0.889807\n",
            "11  Bag of words    stopword + stemmed_words  ...  0.850263  0.889807\n",
            "\n",
            "[12 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGpgukm-THPd"
      },
      "source": [
        "# stopword +lemmatized_words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoisZhM3R_I9",
        "outputId": "9ac0a279-d332-474b-986d-430a4cb56134"
      },
      "source": [
        "#clf=MultinomialNB(alpha=0,fit_prior=True, class_prior=None)  \n",
        "clf=LogisticRegression(class_weight='balanced', solver='newton-cg') \n",
        "vectorizer=TfidfVectorizer(stop_words='english',analyzer = lemmatized_words,ngram_range=(2,3),token_pattern=r'\\b\\w+\\b')\n",
        "tfidf = vectorizer.fit_transform(data_train)\n",
        "tfidf = tfidf.toarray()\n",
        "# Training and Test Split           \n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(tfidf, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "\n",
        "#Classificaion    \n",
        "clf.fit(train_x,train_y)\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 =evaluation(train_x,train_y,test_y,test_x,predicted,'Bag of words', 'stopword +lemmatized_words', df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 37   6   6]\n",
            " [  4 214   5]\n",
            " [  5  14  72]]\n",
            "\n",
            " Precision:0.8898071625344353\n",
            "\n",
            " Recall:0.8898071625344353\n",
            "\n",
            " Macro Averaged F1-Score :0.8476920816339497\n",
            "\n",
            " Mircro Averaged F1-Score:0.8898071625344353\n",
            "           model          preprocessing_used  ...  micro_f1  macro_f1\n",
            "0           demo                        demo  ...  0.000000  0.000000\n",
            "1       Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
            "2       Word2vec              only_stopwords  ...  0.733101  0.804408\n",
            "3       Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
            "4       Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
            "5       Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
            "6       Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
            "7   Bag of words            no_preprocessing  ...  0.681543  0.785124\n",
            "8   Bag of words               only_stopword  ...  0.609205  0.746556\n",
            "9   Bag of words          only_stemmed_words  ...  0.850263  0.889807\n",
            "10  Bag of words       only_lemmatized_words  ...  0.847692  0.889807\n",
            "11  Bag of words    stopword + stemmed_words  ...  0.850263  0.889807\n",
            "12  Bag of words  stopword +lemmatized_words  ...  0.847692  0.889807\n",
            "13  Bag of words  stopword +lemmatized_words  ...  0.847692  0.889807\n",
            "\n",
            "[14 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "Z4Kw4uHPQRUD",
        "outputId": "ce82324b-6a45-41d2-eba0-716c699f0ef1"
      },
      "source": [
        "dfoo = df0.drop(0)\n",
        "dfoo = dfoo.drop(13)\n",
        "dfoo"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>preprocessing_used</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>micro_f1</th>\n",
              "      <th>macro_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Word2vec</td>\n",
              "      <td>no_preprocessing</td>\n",
              "      <td>0.826446</td>\n",
              "      <td>0.826446</td>\n",
              "      <td>0.755451</td>\n",
              "      <td>0.826446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Word2vec</td>\n",
              "      <td>only_stopwords</td>\n",
              "      <td>0.804408</td>\n",
              "      <td>0.804408</td>\n",
              "      <td>0.733101</td>\n",
              "      <td>0.804408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Word2vec</td>\n",
              "      <td>only_stemmed_words</td>\n",
              "      <td>0.809917</td>\n",
              "      <td>0.809917</td>\n",
              "      <td>0.730539</td>\n",
              "      <td>0.809917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Word2vec</td>\n",
              "      <td>only_lemmatized_words</td>\n",
              "      <td>0.820937</td>\n",
              "      <td>0.820937</td>\n",
              "      <td>0.756126</td>\n",
              "      <td>0.820937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Word2vec</td>\n",
              "      <td>stopword + stemmed_words</td>\n",
              "      <td>0.776860</td>\n",
              "      <td>0.776860</td>\n",
              "      <td>0.702064</td>\n",
              "      <td>0.776860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Word2vec</td>\n",
              "      <td>stopword +lemmatized_words</td>\n",
              "      <td>0.801653</td>\n",
              "      <td>0.801653</td>\n",
              "      <td>0.722823</td>\n",
              "      <td>0.801653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bag of words</td>\n",
              "      <td>no_preprocessing</td>\n",
              "      <td>0.785124</td>\n",
              "      <td>0.785124</td>\n",
              "      <td>0.681543</td>\n",
              "      <td>0.785124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bag of words</td>\n",
              "      <td>only_stopword</td>\n",
              "      <td>0.746556</td>\n",
              "      <td>0.746556</td>\n",
              "      <td>0.609205</td>\n",
              "      <td>0.746556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Bag of words</td>\n",
              "      <td>only_stemmed_words</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.850263</td>\n",
              "      <td>0.889807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Bag of words</td>\n",
              "      <td>only_lemmatized_words</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.847692</td>\n",
              "      <td>0.889807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Bag of words</td>\n",
              "      <td>stopword + stemmed_words</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.850263</td>\n",
              "      <td>0.889807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bag of words</td>\n",
              "      <td>stopword +lemmatized_words</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.847692</td>\n",
              "      <td>0.889807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           model          preprocessing_used  ...  micro_f1  macro_f1\n",
              "1       Word2vec            no_preprocessing  ...  0.755451  0.826446\n",
              "2       Word2vec              only_stopwords  ...  0.733101  0.804408\n",
              "3       Word2vec          only_stemmed_words  ...  0.730539  0.809917\n",
              "4       Word2vec       only_lemmatized_words  ...  0.756126  0.820937\n",
              "5       Word2vec    stopword + stemmed_words  ...  0.702064  0.776860\n",
              "6       Word2vec  stopword +lemmatized_words  ...  0.722823  0.801653\n",
              "7   Bag of words            no_preprocessing  ...  0.681543  0.785124\n",
              "8   Bag of words               only_stopword  ...  0.609205  0.746556\n",
              "9   Bag of words          only_stemmed_words  ...  0.850263  0.889807\n",
              "10  Bag of words       only_lemmatized_words  ...  0.847692  0.889807\n",
              "11  Bag of words    stopword + stemmed_words  ...  0.850263  0.889807\n",
              "12  Bag of words  stopword +lemmatized_words  ...  0.847692  0.889807\n",
              "\n",
              "[12 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXrkR33_w4dU"
      },
      "source": [
        "dfoo.to_csv('/content/preprocessing_result_csv.csv', index= None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "red9n4DoQUvI",
        "outputId": "8b3282b4-c10d-4886-cb20-60f7aa3160ab"
      },
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english',ngram_range=(1,1))\n",
        "X = vectorizer.fit_transform(data_train)\n",
        "#create dataframe\n",
        "cv_dataframe=pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
        "print(cv_dataframe)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       00  000  002  0025  003  0030  ...   ñn  ñnekoski  ñnnen  ñrnits  ñrvi  ñskyl\n",
            "0     0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "1     0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "2     0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "3     0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "4     0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "...   ...  ...  ...   ...  ...   ...  ...  ...       ...    ...     ...   ...    ...\n",
            "1806  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "1807  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "1808  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "1809  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "1810  0.0  0.0  0.0   0.0  0.0   0.0  ...  0.0       0.0    0.0     0.0   0.0    0.0\n",
            "\n",
            "[1811 rows x 5205 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq2-7tLHxVYz",
        "outputId": "e7fa4f1a-173d-479e-ed1a-c83c37b5f26d"
      },
      "source": [
        "X_train_word_average.shape,X_test_word_average.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1448, 300), (363, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4soaSo8zh3z"
      },
      "source": [
        "#logistic_regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af1rK77zjcLE",
        "outputId": "aa4e480c-0d61-45e4-8caa-b03feb24b28e"
      },
      "source": [
        "train_x, test_x, train_y, test_y = train_test_split(data_train, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "#Classifier\n",
        "clf=LogisticRegression(class_weight='balanced') \n",
        "clf_parameters = {'clf__solver':('newton-cg','lbfgs','liblinear'),}    \n",
        "        \n",
        "#Feature Extraction\n",
        "pipeline = Pipeline([\n",
        "('vect', CountVectorizer(token_pattern=r'\\b\\w+\\b')),\n",
        "('tfidf', TfidfTransformer(use_idf=True,smooth_idf=True)),     \n",
        "('clf', clf),]) \n",
        "    \n",
        "feature_parameters = {\n",
        "\"vect__stop_words\": (None, 'english'),\n",
        "'vect__analyzer':(stemmed_words, lemmatized_words),\n",
        "'vect__min_df': (2,3),\n",
        "'vect__ngram_range': ((1,1),(1, 2),(1,3),(2,3)),  # Unigrams, Bigrams or Trigrams\n",
        "}\n",
        "\n",
        "#Classificaion\n",
        "parameters={**feature_parameters,**clf_parameters} \n",
        "grid = GridSearchCV(pipeline,parameters,scoring='f1_micro',cv=10)          \n",
        "grid.fit(train_x,train_y)     \n",
        "clf= grid.best_estimator_  \n",
        "print('********* Best Set of Parameters ********* \\n\\n')\n",
        "print(clf)\n",
        "\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(train_x,train_y,test_y,test_x,predicted,'logistic_regression',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* Best Set of Parameters ********* \n",
            "\n",
            "\n",
            "Pipeline(memory=None,\n",
            "         steps=[('vect',\n",
            "                 CountVectorizer(analyzer=<function stemmed_words at 0x7f3925fa9170>,\n",
            "                                 binary=False, decode_error='strict',\n",
            "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
            "                                 input='content', lowercase=True, max_df=1.0,\n",
            "                                 max_features=None, min_df=3,\n",
            "                                 ngram_range=(1, 1), preprocessor=None,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 token_pattern='\\\\b\\\\w+\\\\b', tok...\n",
            "                ('tfidf',\n",
            "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
            "                                  sublinear_tf=False, use_idf=True)),\n",
            "                ('clf',\n",
            "                 LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                                    fit_intercept=True, intercept_scaling=1,\n",
            "                                    l1_ratio=None, max_iter=100,\n",
            "                                    multi_class='auto', n_jobs=None,\n",
            "                                    penalty='l2', random_state=None,\n",
            "                                    solver='newton-cg', tol=0.0001, verbose=0,\n",
            "                                    warm_start=False))],\n",
            "         verbose=False)\n",
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 40   5   4]\n",
            " [  4 211   8]\n",
            " [  7   9  75]]\n",
            "\n",
            " Precision:0.8980716253443526\n",
            "\n",
            " Recall:0.8980716253443526\n",
            "\n",
            " Macro Averaged F1-Score :0.8615536383092564\n",
            "\n",
            " Mircro Averaged F1-Score:0.8980716253443526\n",
            "                 model  precision    recall  micro_f1  macro_f1\n",
            "0                 demo   0.000000  0.000000  0.000000  0.000000\n",
            "1        random_forest   0.820937  0.820937  0.756126  0.820937\n",
            "2  logistic_regression   0.820937  0.820937  0.756126  0.820937\n",
            "3                  SVM   0.757576  0.757576  0.620901  0.757576\n",
            "4        random_forest   0.768595  0.768595  0.636111  0.768595\n",
            "5  logistic_regression   0.898072  0.898072  0.861554  0.898072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cissqob5laS"
      },
      "source": [
        "results = clf.predict(data_test)\n",
        "results.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81Twv6R9582f",
        "outputId": "e93f9ff1-e64e-41d1-aee1-3f67ed5f4775"
      },
      "source": [
        "len(results), len(data_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(453, 453)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSygfRHM6uFo"
      },
      "source": [
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ghTVuOn66IdW",
        "outputId": "4789c2ae-b21a-441c-81d0-c734f403e64c"
      },
      "source": [
        "df11 = pd.DataFrame()\n",
        "df11['labels']= results\n",
        "df11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>453 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       labels\n",
              "0    positive\n",
              "1     neutral\n",
              "2    negative\n",
              "3     neutral\n",
              "4    positive\n",
              "..        ...\n",
              "448  negative\n",
              "449   neutral\n",
              "450   neutral\n",
              "451  positive\n",
              "452   neutral\n",
              "\n",
              "[453 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dry6s74n6PEN"
      },
      "source": [
        "df11.to_csv('test_labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwMcZe1bzvWm"
      },
      "source": [
        "#naive_baies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiT8u2_ns1zx",
        "outputId": "4e764171-35d7-4617-d587-da5b77316aaf"
      },
      "source": [
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(data_train, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "#Classifier\n",
        "clf=MultinomialNB(fit_prior=True, class_prior=None)\n",
        "\n",
        "clf_parameters = {'clf__alpha':(0,1,2),}    \n",
        "        \n",
        "#Feature Extraction\n",
        "pipeline = Pipeline([\n",
        "('vect', CountVectorizer(token_pattern=r'\\b\\w+\\b')),\n",
        "('tfidf', TfidfTransformer(use_idf=True,smooth_idf=True)),     \n",
        "('clf', clf),]) \n",
        "    \n",
        "feature_parameters = {\n",
        "\"vect__stop_words\": (None, 'english'),\n",
        "'vect__analyzer':(stemmed_words, lemmatized_words),\n",
        "'vect__min_df': (2,3),\n",
        "'vect__ngram_range': ((1,1),(1, 2),(1,3),(2,3)),  # Unigrams, Bigrams or Trigrams\n",
        "}\n",
        "\n",
        "#Classificaion\n",
        "parameters={**feature_parameters,**clf_parameters} \n",
        "grid = GridSearchCV(pipeline,parameters,scoring='f1_micro',cv=10)          \n",
        "grid.fit(train_x,train_y)     \n",
        "clf= grid.best_estimator_  \n",
        "print('********* Best Set of Parameters ********* \\n\\n')\n",
        "print(clf)\n",
        "\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(train_x,train_y,test_y,test_x,predicted, 'naive_bayes',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* Best Set of Parameters ********* \n",
            "\n",
            "\n",
            "Pipeline(memory=None,\n",
            "         steps=[('vect',\n",
            "                 CountVectorizer(analyzer=<function lemmatized_words at 0x7fe4370ac3b0>,\n",
            "                                 binary=False, decode_error='strict',\n",
            "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
            "                                 input='content', lowercase=True, max_df=1.0,\n",
            "                                 max_features=None, min_df=3,\n",
            "                                 ngram_range=(1, 1), preprocessor=None,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 token_pattern='\\\\b\\\\w+\\\\b', tokenizer=None,\n",
            "                                 vocabulary=None)),\n",
            "                ('tfidf',\n",
            "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
            "                                  sublinear_tf=False, use_idf=True)),\n",
            "                ('clf',\n",
            "                 MultinomialNB(alpha=0, class_prior=None, fit_prior=True))],\n",
            "         verbose=False)\n",
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 26  11  12]\n",
            " [  4 211   8]\n",
            " [  8  24  59]]\n",
            "\n",
            " Precision:0.8154269972451791\n",
            "\n",
            " Recall:0.8154269972451791\n",
            "\n",
            " Macro Averaged F1-Score :0.7305351922893021\n",
            "\n",
            " Mircro Averaged F1-Score:0.8154269972451791\n",
            "                 model  precision    recall  micro_f1  macro_f1\n",
            "0                 demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  logistic_regression   0.898072  0.898072  0.861554  0.898072\n",
            "2          naive_bayes   0.815427  0.815427  0.730535  0.815427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efjTS574z1VN"
      },
      "source": [
        "#SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1fq-igAz0th",
        "outputId": "6e0cbb2b-cf8d-4193-bcb0-af3c2d72987c"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "train_x, test_x, train_y, test_y = train_test_split(data_train, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "#Classifier\n",
        "clf=SVC()\n",
        "\n",
        "clf_parameters = {'clf__kernel':('linear', 'poly'),#, 'rbf', 'sigmoid'),\n",
        "                  'clf__C' : (0,1),#,3,5,10),\n",
        "                  }    \n",
        "        \n",
        "#Feature Extraction\n",
        "pipeline = Pipeline([\n",
        "('vect', CountVectorizer(token_pattern=r'\\b\\w+\\b')),\n",
        "('tfidf', TfidfTransformer(use_idf=True,smooth_idf=True)),     \n",
        "('clf', clf),]) \n",
        "    \n",
        "feature_parameters = {\n",
        "#\"vect__stop_words\": (None, 'english'),\n",
        "'vect__analyzer':(stemmed_words, lemmatized_words),\n",
        "'vect__min_df': (2,3),\n",
        "'vect__ngram_range': ((2,3),(1,1))#,(1, 2),(1,3)),  # Unigrams, Bigrams or Trigrams\n",
        "}\n",
        "\n",
        "#Classificaion\n",
        "parameters={**feature_parameters,**clf_parameters} \n",
        "grid = GridSearchCV(pipeline,parameters,scoring='f1_micro',cv=10)          \n",
        "grid.fit(train_x,train_y)     \n",
        "clf= grid.best_estimator_  \n",
        "print('********* Best Set of Parameters ********* \\n\\n')\n",
        "print(clf)\n",
        "\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(train_x,train_y,test_y,test_x,predicted,'svm',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: b'C <= 0'\n",
            "\n",
            "  FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* Best Set of Parameters ********* \n",
            "\n",
            "\n",
            "Pipeline(memory=None,\n",
            "         steps=[('vect',\n",
            "                 CountVectorizer(analyzer=<function stemmed_words at 0x7fe4370ac170>,\n",
            "                                 binary=False, decode_error='strict',\n",
            "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
            "                                 input='content', lowercase=True, max_df=1.0,\n",
            "                                 max_features=None, min_df=2,\n",
            "                                 ngram_range=(2, 3), preprocessor=None,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 token_pattern='\\\\b\\\\w+\\\\b', tok...\n",
            "                                 vocabulary=None)),\n",
            "                ('tfidf',\n",
            "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
            "                                  sublinear_tf=False, use_idf=True)),\n",
            "                ('clf',\n",
            "                 SVC(C=1, break_ties=False, cache_size=200, class_weight=None,\n",
            "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
            "                     gamma='scale', kernel='linear', max_iter=-1,\n",
            "                     probability=False, random_state=None, shrinking=True,\n",
            "                     tol=0.001, verbose=False))],\n",
            "         verbose=False)\n",
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 33   7   9]\n",
            " [  0 216   7]\n",
            " [  2  20  69]]\n",
            "\n",
            " Precision:0.8760330578512396\n",
            "\n",
            " Recall:0.8760330578512396\n",
            "\n",
            " Macro Averaged F1-Score :0.8322812738048789\n",
            "\n",
            " Mircro Averaged F1-Score:0.8760330578512396\n",
            "                 model  precision    recall  micro_f1  macro_f1\n",
            "0                 demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  logistic_regression   0.898072  0.898072  0.861554  0.898072\n",
            "2          naive_bayes   0.815427  0.815427  0.730535  0.815427\n",
            "3                  svm   0.876033  0.876033  0.832281  0.876033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvjvyMAtuDoR"
      },
      "source": [
        "#random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnwuCQreIulD",
        "outputId": "42b6244e-6e83-44dc-f7bc-d61d8b118217"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "train_x, test_x, train_y, test_y = train_test_split(data_train, labels_train, test_size=0.20, random_state=42,stratify=labels_train)\n",
        "#Classifier\n",
        "clf=RandomForestClassifier(random_state=42,n_estimators = 10)\n",
        "\n",
        "clf_parameters = {'clf__criterion':('gini', 'entropy'),\n",
        "                  'clf__max_depth' : (65,66,67,68,69,70),\n",
        "                  'clf__max_features':('auto',0.75,0.8,0.4),\n",
        "                  }    \n",
        "        \n",
        "#Feature Extraction\n",
        "pipeline = Pipeline([\n",
        "('vect', CountVectorizer(token_pattern=r'\\b\\w+\\b')),\n",
        "('tfidf', TfidfTransformer(use_idf=True,smooth_idf=True)),     \n",
        "('clf', clf),]) \n",
        "    \n",
        "feature_parameters = {\n",
        "#\"vect__stop_words\": (None, 'english'),\n",
        "'vect__analyzer':(stemmed_words, lemmatized_words),\n",
        "'vect__min_df': (2,3),\n",
        "'vect__ngram_range': ((2,3),(1,1))#,(1, 2),(1,3)),  # Unigrams, Bigrams or Trigrams\n",
        "}\n",
        "\n",
        "#Classificaion\n",
        "parameters={**feature_parameters,**clf_parameters} \n",
        "grid = GridSearchCV(pipeline,parameters,scoring='f1_micro',cv=10)          \n",
        "grid.fit(train_x,train_y)     \n",
        "clf= grid.best_estimator_  \n",
        "print('********* Best Set of Parameters ********* \\n\\n')\n",
        "print(clf)\n",
        "\n",
        "predicted = clf.predict(test_x)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(train_x,train_y,test_y,test_x,predicted,'random_forest',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* Best Set of Parameters ********* \n",
            "\n",
            "\n",
            "Pipeline(memory=None,\n",
            "         steps=[('vect',\n",
            "                 CountVectorizer(analyzer=<function stemmed_words at 0x7fe4370ac170>,\n",
            "                                 binary=False, decode_error='strict',\n",
            "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
            "                                 input='content', lowercase=True, max_df=1.0,\n",
            "                                 max_features=None, min_df=2,\n",
            "                                 ngram_range=(2, 3), preprocessor=None,\n",
            "                                 stop_words=None, strip_accents=None,\n",
            "                                 token_pattern='\\\\b\\\\w+\\\\b', tok...\n",
            "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
            "                                        class_weight=None, criterion='gini',\n",
            "                                        max_depth=65, max_features=0.4,\n",
            "                                        max_leaf_nodes=None, max_samples=None,\n",
            "                                        min_impurity_decrease=0.0,\n",
            "                                        min_impurity_split=None,\n",
            "                                        min_samples_leaf=1, min_samples_split=2,\n",
            "                                        min_weight_fraction_leaf=0.0,\n",
            "                                        n_estimators=10, n_jobs=None,\n",
            "                                        oob_score=False, random_state=42,\n",
            "                                        verbose=0, warm_start=False))],\n",
            "         verbose=False)\n",
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 26  13  10]\n",
            " [  0 213  10]\n",
            " [  6  20  65]]\n",
            "\n",
            " Precision:0.837465564738292\n",
            "\n",
            " Recall:0.837465564738292\n",
            "\n",
            " Macro Averaged F1-Score :0.7629757457701073\n",
            "\n",
            " Mircro Averaged F1-Score:0.837465564738292\n",
            "                 model  precision    recall  micro_f1  macro_f1\n",
            "0                 demo   0.000000  0.000000  0.000000  0.000000\n",
            "1  logistic_regression   0.898072  0.898072  0.861554  0.898072\n",
            "2          naive_bayes   0.815427  0.815427  0.730535  0.815427\n",
            "3                  svm   0.876033  0.876033  0.832281  0.876033\n",
            "4        random_forest   0.837466  0.837466  0.762976  0.837466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIy4KKd0MOCB"
      },
      "source": [
        "df0.to_csv('/content/bagofwords_on_models_result_csv.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLv7ywPjb0yg"
      },
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zd8-KQ2b2DC"
      },
      "source": [
        "# word_to_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alG-8cXLcCRp"
      },
      "source": [
        "#logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4lI-2fJuBh0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cd1c48-ca0e-4837-946b-35c00e509648"
      },
      "source": [
        "\n",
        "    \n",
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text, args= (4,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "# clf=RandomForestClassifier(random_state=42,n_estimators = 10)\n",
        "\n",
        "# clf_parameters = {'criterion':('gini', 'entropy'),\n",
        "#                   'max_depth' : (65,66),#,67,68,69,70),\n",
        "#                   'max_features':('auto',0.75),#,0.8,0.4),\n",
        "#                   }    \n",
        "        \n",
        "clf=LogisticRegression(class_weight='balanced') \n",
        "clf_parameters = {'solver':('newton-cg','lbfgs','liblinear'),}\n",
        " \n",
        "grid = GridSearchCV(clf, clf_parameters, scoring='f1_micro',cv=10)          \n",
        "grid.fit(X_train_word_average,train_y)     \n",
        "clf= grid.best_estimator_  \n",
        "print('********* Best Set of Parameters ********* \\n\\n')\n",
        "print(clf)\n",
        "\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'logistic_regression',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 34802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* Best Set of Parameters ********* \n",
            "\n",
            "\n",
            "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
            "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
            "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 39   4   9]\n",
            " [  9 200  10]\n",
            " [ 18  15  59]]\n",
            "\n",
            " Precision:0.8209366391184573\n",
            "\n",
            " Recall:0.8209366391184573\n",
            "\n",
            " Macro Averaged F1-Score :0.7561255351145952\n",
            "\n",
            " Mircro Averaged F1-Score:0.8209366391184573\n",
            "                 model  precision    recall  micro_f1  macro_f1\n",
            "0                 demo   0.000000  0.000000  0.000000  0.000000\n",
            "1        random_forest   0.820937  0.820937  0.756126  0.820937\n",
            "2  logistic_regression   0.820937  0.820937  0.756126  0.820937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bzigHVidHlH",
        "outputId": "3a6781f3-732c-4d88-8687-f4479d43736e"
      },
      "source": [
        "\n",
        "    \n",
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text, args= (4,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "clf=RandomForestClassifier(random_state=42,n_estimators = 10)\n",
        "\n",
        "clf_parameters = {'criterion':('gini', 'entropy'),\n",
        "                  'max_depth' : (65,66),#,67,68,69,70),\n",
        "                  'max_features':('auto',0.75),#,0.8,0.4),\n",
        "                  }    \n",
        "        \n",
        "# clf=LogisticRegression(class_weight='balanced') \n",
        "# clf_parameters = {'solver':('newton-cg','lbfgs','liblinear'),}\n",
        "# clf=MultinomialNB(fit_prior=True, class_prior=None)\n",
        "\n",
        "# clf_parameters = {'alpha':(0,1,2),}    \n",
        "        \n",
        " \n",
        "grid = GridSearchCV(clf, clf_parameters, scoring='f1_micro',cv=10)          \n",
        "grid.fit(X_train_word_average,train_y)     \n",
        "clf= grid.best_estimator_  \n",
        "print('********* Best Set of Parameters ********* \\n\\n')\n",
        "print(clf)\n",
        "\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'SVM',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 34802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* Best Set of Parameters ********* \n",
            "\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=65, max_features=0.75,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
            "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False)\n",
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 17  15  20]\n",
            " [  2 209   8]\n",
            " [ 15  28  49]]\n",
            "\n",
            " Precision:0.7575757575757576\n",
            "\n",
            " Recall:0.7575757575757576\n",
            "\n",
            " Macro Averaged F1-Score :0.6209013182453015\n",
            "\n",
            " Mircro Averaged F1-Score:0.7575757575757576\n",
            "                 model  precision    recall  micro_f1  macro_f1\n",
            "0                 demo   0.000000  0.000000  0.000000  0.000000\n",
            "1        random_forest   0.820937  0.820937  0.756126  0.820937\n",
            "2  logistic_regression   0.820937  0.820937  0.756126  0.820937\n",
            "3                  SVM   0.757576  0.757576  0.620901  0.757576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExDkCCqedhTl",
        "outputId": "35002a12-f1a2-4805-c655-e8f8b72087ca"
      },
      "source": [
        "\n",
        "    \n",
        "df_train = pd.DataFrame(data_train)\n",
        "print('words_per before',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "\n",
        "df_train[0] = df_train[0].apply(clean_text, args= (4,))\n",
        "print('words_per after',df_train[0].apply(lambda x: len(x.split(' '))).sum())\n",
        "  \n",
        "train_x, test_x, train_y, test_y = train_test_split(df_train, labels_train, test_size=0.2, random_state = 42)\n",
        "\n",
        "test_tokenized = test_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "train_tokenized = train_x.apply(lambda r: w2v_tokenize_text(r[0]), axis=1).values\n",
        "\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)\n",
        "\n",
        "# clf=RandomForestClassifier(random_state=42,n_estimators = 10)\n",
        "\n",
        "# clf_parameters = {'criterion':('gini', 'entropy'),\n",
        "#                   'max_depth' : (65,66),#,67,68,69,70),\n",
        "#                   'max_features':('auto',0.75),#,0.8,0.4),\n",
        "#                   }    \n",
        "        \n",
        "# clf=LogisticRegression(class_weight='balanced') \n",
        "# clf_parameters = {'solver':('newton-cg','lbfgs','liblinear'),}\n",
        "clf=RandomForestClassifier(random_state=42,n_estimators = 10)\n",
        "\n",
        "clf_parameters = {'criterion':('gini', 'entropy'),\n",
        "                  'max_depth' : (65,66,67,68,69,70),\n",
        "                  'max_features':('auto',0.75,0.8,0.4),\n",
        "                  }  \n",
        " \n",
        "grid = GridSearchCV(clf, clf_parameters, scoring='f1_micro',cv=10)          \n",
        "grid.fit(X_train_word_average,train_y)     \n",
        "clf= grid.best_estimator_  \n",
        "print('********* Best Set of Parameters ********* \\n\\n')\n",
        "print(clf)\n",
        "\n",
        "predicted = clf.predict(X_test_word_average)\n",
        "predicted =list(predicted)\n",
        "df0 = evaluation(X_train_word_average,train_y,test_y,X_test_word_average,predicted,'random_forest',df0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words_per before 40627\n",
            "words_per after 34802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  app.launch_new_instance()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "********* Best Set of Parameters ********* \n",
            "\n",
            "\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='entropy', max_depth=65, max_features=0.4,\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
            "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
            "                       warm_start=False)\n",
            "\n",
            " Total documents in the training set: 1448\n",
            "\n",
            "\n",
            " Total documents in the test set: 363\n",
            "\n",
            "\n",
            " Confusion Matrix \n",
            "\n",
            "[[ 17  17  18]\n",
            " [  1 211   7]\n",
            " [ 12  29  51]]\n",
            "\n",
            " Precision:0.768595041322314\n",
            "\n",
            " Recall:0.768595041322314\n",
            "\n",
            " Macro Averaged F1-Score :0.6361105417776867\n",
            "\n",
            " Mircro Averaged F1-Score:0.768595041322314\n",
            "                 model  precision    recall  micro_f1  macro_f1\n",
            "0                 demo   0.000000  0.000000  0.000000  0.000000\n",
            "1        random_forest   0.820937  0.820937  0.756126  0.820937\n",
            "2  logistic_regression   0.820937  0.820937  0.756126  0.820937\n",
            "3                  SVM   0.757576  0.757576  0.620901  0.757576\n",
            "4        random_forest   0.768595  0.768595  0.636111  0.768595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jduMM0T0t_MW"
      },
      "source": [
        "ss= df0.drop(0)\n",
        "ss= ss.drop(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odWvajC9hx2w"
      },
      "source": [
        "ss.to_csv('\\content\\wor2vec on classifier.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iUkFnlCCBye"
      },
      "source": [
        "ss= df1.drop(0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "t3kqS7f3Mfwb",
        "outputId": "8000d173-88e4-4bab-b1e5-4779dc7abb72"
      },
      "source": [
        "ss\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>micro_f1</th>\n",
              "      <th>macro_f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>logistic_regression</td>\n",
              "      <td>0.983857</td>\n",
              "      <td>0.983857</td>\n",
              "      <td>0.964941</td>\n",
              "      <td>0.983857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>naive_bayes</td>\n",
              "      <td>0.977578</td>\n",
              "      <td>0.977578</td>\n",
              "      <td>0.949102</td>\n",
              "      <td>0.977578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>svm</td>\n",
              "      <td>0.982063</td>\n",
              "      <td>0.982063</td>\n",
              "      <td>0.959650</td>\n",
              "      <td>0.982063</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  name  precision    recall  micro_f1  macro_f1\n",
              "1  logistic_regression   0.983857  0.983857  0.964941  0.983857\n",
              "2          naive_bayes   0.977578  0.977578  0.949102  0.977578\n",
              "3                  svm   0.982063  0.982063  0.959650  0.982063"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgNz-kpWxKtB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}